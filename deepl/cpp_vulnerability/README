sudo unlink /usr/bin/cmake
sudo ln -s ~/cmake-3.22.6/bin/cmake /usr/bin/cmake
sudo apt install -y ninja-build

cd ~/Python-3.9.18
sudo make install
sudo unlink /usr/bin/python
sudo ln -s /usr/local/bin/python3 /usr/bin/python
cd --


sudo apt install -y clang clang-tidy cppcheck

# Install Ollama
sudo curl -fsSL https://ollama.com/install.sh | sh

# Download open-source model
# https://ollama.com/library/
ollama pull qwen3:8b

# Run a model
ollama run qwen3:8b 

sudo apt update
sudo apt install python3
python3 -m venv ~/src/dl/ollama_env



source /home/worker/src/dl/ollama_env/bin/activate
pip install ollama

TODO:
lay vi du tao 1 client ket noi copilot qua copilot language server.
https://github.com/github/copilot-language-server-release

client can request kiem tra vi pham code c++ cua 1 doan ma.